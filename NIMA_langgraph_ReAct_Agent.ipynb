{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBORx/BQYMXkV9gw/uzxYS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanDao01262000/nima-agent/blob/nima_langgraph_agent/NIMA_langgraph_ReAct_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install libraries for the project"
      ],
      "metadata": {
        "id": "FniGposFz9Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langgraph langsmith langchain_community langchain_openai langchain_core langchain_pinecone cinemagoer"
      ],
      "metadata": {
        "id": "MzFSnMpcXYp1"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get(\"OPENAI_API_KEY\")\n",
        "llm_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "rS6jPCeGzokU"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imdb import Cinemagoer\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def fetch_movie_info_from_TMDB_tool(movie_name: str) -> str:\n",
        "    \"\"\"Useful for when you give any information about a particular movie on TMDB\"\"\"\n",
        "    cine = Cinemagoer()\n",
        "    movie_id = cine.search_movie(movie_name)[0].movieID\n",
        "    movie = cine.get_movie(movie_id)\n",
        "\n",
        "    info_keys =['localized title', 'cast', 'genres', 'runtimes', 'countries', 'plot'\n",
        "    'box office', 'certificates', 'original air date', 'synopsis', 'rating', 'votes', 'cover url', 'imdbID', 'videos', 'languages',\n",
        "  'title', 'year', 'kind', 'original title', 'director', 'writer', 'producer', 'composer', 'production companies', 'distributors']\n",
        "\n",
        "    res = \"\"\n",
        "    for key in info_keys:\n",
        "        info_str = \"\"\n",
        "        info_set = movie.get(key)\n",
        "        if isinstance(info_set, list):\n",
        "            for i, info in enumerate(info_set[:5]):\n",
        "              info_str += f\"{str(info)}\"\n",
        "              if i != min(len(info_set)-1,4):\n",
        "                info_str += \", \"\n",
        "\n",
        "\n",
        "        elif isinstance(info_set, dict):\n",
        "            for key, value in info_set.items():\n",
        "              info_str += f\"{key}: {str(value)}, \"\n",
        "\n",
        "        else:\n",
        "            info_str =  str(info_set)\n",
        "        res += f\"{key.upper()}: {info_str}./n \"\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "MqVKJiNYdIMo"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool check whether the input is related to the movie topic or not\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def input_judgement_tool(user_input: str) ->str:\n",
        "    \"\"\" Useful for checking whether the question from user is related to movie topics or not\"\"\"\n",
        "    prompt = f\"Check whether the following input is related to movie, answer either YES or NO. Input: {user_input}\"\n",
        "    response =llm_model.invoke(prompt)\n",
        "    return response"
      ],
      "metadata": {
        "id": "ZFhdD1bfHM4q"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test input_jugdement_tool\n",
        "# input_judgement_tool.invoke('what is 1 + 2')"
      ],
      "metadata": {
        "id": "YWWbnXKmIU5m"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from google.colab import userdata\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def google_search(user_input: str) -> str:\n",
        "    '''Useful for when you recommend new movies, or find any information relating to movies but need to call get_curernt_time_tool to get correct time.'''\n",
        "    google_search = GoogleSerperAPIWrapper(serper_api_key=userdata.get(\"SERPER_API_KEY\"))\n",
        "    return google_search.run(user_input)\n"
      ],
      "metadata": {
        "id": "I1sflofFeI7n"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# google_search.invoke('who is the winner of the best actor in Oscar 2024')"
      ],
      "metadata": {
        "id": "fYAiCE3_er5y"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "device = 'cpu'\n",
        "\n",
        "embed_model = HuggingFaceEmbeddings(model_name=model_id,\n",
        "                            model_kwargs={\"device\":device},\n",
        "                            encode_kwargs={\"device\":device,\n",
        "                                            \"batch_size\":200})\n"
      ],
      "metadata": {
        "id": "v2VT9xhyqcyB"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import Pinecone\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone as P\n",
        "\n",
        "\n",
        "# about-me client for Nima's information rag\n",
        "api_key_about_me = userdata.get(\"PINECONE_API_KEY_1\")\n",
        "pc_about_me = P(api_key=api_key_about_me)\n",
        "index_name_1 = \"nima-information\"\n",
        "index_about_me = pc_about_me.Index(index_name_1)\n",
        "vectorstore_about_me = Pinecone(\n",
        "    index_about_me, embed_model, \"information\"\n",
        ")\n",
        "\n",
        "retriever_about_me = vectorstore_about_me.as_retriever()"
      ],
      "metadata": {
        "id": "_fHBCBhlomq7"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retriever_about_me.invoke('Tan Dao')"
      ],
      "metadata": {
        "id": "xHzUd28Iqzfw"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import Pinecone\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone as P\n",
        "\n",
        "\n",
        "# about-me client for Nima's information rag\n",
        "api_key = userdata.get(\"PINECONE_API_KEY_2\")\n",
        "pc = P(api_key=api_key)\n",
        "index_name = \"nima1\"\n",
        "index = pc.Index(index_name)\n",
        "vectorstore = Pinecone(\n",
        "    index, embed_model, \"text\"\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={'k': 10})"
      ],
      "metadata": {
        "id": "mPmaYqiBZyIc"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retriever.invoke('harry potter')"
      ],
      "metadata": {
        "id": "kbJRmywBko8f"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_pinecone import Pinecone\n",
        "\n",
        "template = '''\n",
        "    You are Nima. You will do your best to recommend movies based on the question and context.\n",
        "    You are also an expert in movies. Using your knowledge and based on the details provided\n",
        "    below, analyse do your best to provide movie recommendations that will appease\n",
        "    to the person asking for movie recommendations.\n",
        "\n",
        "    Always make sure that your recommendations are fair, unbiased, and don't take any\n",
        "    kind of detail into consideration such as ethnicity, gender, age, race, religion,\n",
        "    and so on.\n",
        "\n",
        "    If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question: {question}\n",
        "    Answer:\n",
        "    '''\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\n",
        "        'context',\n",
        "        'question',\n",
        "    ]\n",
        ")\n",
        "\n",
        "rag_pipeline = RetrievalQA.from_chain_type(llm=llm_model,\n",
        "                                    chain_type=\"stuff\",\n",
        "                                    retriever=retriever,\n",
        "                                    chain_type_kwargs={\"prompt\": prompt})"
      ],
      "metadata": {
        "id": "6dq7yUwskTBy"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test recommendation pipeline\n",
        "# rag_pipeline.invoke('i love the harry potter series so much, can you recommend me some similar')"
      ],
      "metadata": {
        "id": "0p0A1XOvjTr8"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "@tool\n",
        "def movies_recommendaion_tool(query: str) -> str:\n",
        "    ''' Useful when you recommend movies based on a static movie dataset '''\n",
        "    return rag_pipeline.invoke(query)"
      ],
      "metadata": {
        "id": "2aiOITLxkzBO"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def get_movies_for_recommendation_tool(query: str) -> list[Document]:\n",
        "    ''' Useful when you recommend movies on a static movie dataset '''\n",
        "    return retriever.invoke(query)"
      ],
      "metadata": {
        "id": "2Z_LW6L2nH1n"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def retriever_about_me_tool(query : str) -> list[Document]:\n",
        "    ''' Useful when you need information about yourself/NIMA or relating to you '''\n",
        "    return retriever_about_me.invoke(query)"
      ],
      "metadata": {
        "id": "S4YcdzPDsFba"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google search tool\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.tools import tool\n",
        "from google.colab import userdata\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "\n",
        "@tool\n",
        "def google_search_tool(query: str) -> str:\n",
        "    ''' Useful for all situations, especially when the question asks for new information or information that can find on google. '''\n",
        "    google_search = GoogleSerperAPIWrapper(serper_api_key=userdata.get(\"SERPER_API_KEY\"))\n",
        "    return google_search.run(query)\n"
      ],
      "metadata": {
        "id": "TXSg_iMpUkJa"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# google_search_tool('new movies to watch')"
      ],
      "metadata": {
        "id": "QR4v0hq-YRL1"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get current time\n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "current_time = f\"Today is: {now.strftime('%A, %d %B %Y, %H:%M') }\""
      ],
      "metadata": {
        "id": "XwypWdE5da4r"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_curernt_time_tool() -> str:\n",
        "    ''' Useful when you need to know the current time before seaching for real time information on search engine'''\n",
        "    return current_time"
      ],
      "metadata": {
        "id": "aIRIFTguf8-v"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of tools for NIMA\n",
        "tools = [ input_judgement_tool,\n",
        "          fetch_movie_info_from_TMDB_tool,\n",
        "          google_search,\n",
        "          retriever_about_me_tool,\n",
        "          movies_recommendaion_tool,\n",
        "          get_curernt_time_tool,\n",
        "          google_search_tool\n",
        "        ]"
      ],
      "metadata": {
        "id": "MuQaajw-bksO"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define system prompt\n",
        "\n",
        "prompt = '''\n",
        "Your name is Nima, an acronym for \"Now I Movie Anytime\". Created by the innovative team also named Nima, as part of their senior project.\n",
        "You embody the collective expertise of its four creators: Do Tran, Quyen Nguyen, Michael Kao, and Tan Dao.\n",
        "\n",
        "You are able to generate human-like text based on the input it receives,\n",
        "allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic about movies or relating to movies.\n",
        "\n",
        "You are constantly learning and improving, and its capabilities are constantly evolving.\n",
        "It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses on movie topic.\n",
        "Additionally, NIMA is able to generate its own text based on the input it receives,\n",
        "allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
        "\n",
        "Overall, you are a powerful assistant that can have conversation on only movie relating topics.\n",
        "Whether you need help with a specific question or just want to have a conversation about a particular topic, Nima is here to assist.\"\n",
        "\n",
        "MUST DO:\n",
        "    --------\n",
        "    * input_judgement_tool: Always call this tool first to see if the input is related to movie topics, if not, refuse to answer politely.\n",
        "    * get_curernt_time_tool: Always call this tool secondly to get the current day\n",
        "\n",
        "NOTES:\n",
        "    --------\n",
        "    Nima is human-like assistant, so always answer like a human and in a conversation with the users.\n",
        "    Every response should be in very deep detailed and asking if the users still need help at the end of each response.\n",
        "\n",
        "'''\n",
        "\n",
        "# Combine both current datetime with system prompt\n",
        "prompt = prompt"
      ],
      "metadata": {
        "id": "bDuphOxJuhwm"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define chat memory\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "memory = MemorySaver()"
      ],
      "metadata": {
        "id": "4ieEvjDdmjyP"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the graph\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "graph = create_react_agent(llm_model, tools=tools, state_modifier=prompt, checkpointer=memory)"
      ],
      "metadata": {
        "id": "D01a9P7ldtwD"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test NIMA agent"
      ],
      "metadata": {
        "id": "xhOhh3Yc4Dmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test NIMA\n",
        "# config = {\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}}  # Configuration for memory storage\n",
        "# inputs = {\"messages\": [(\"user\", \"any other series or trilogy similar to it so i can enjoy \")]}\n",
        "# message = graph.invoke(inputs, config = config)[\"messages\"][-1]\n",
        "# message.pretty_print()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ewLMPMaT0W9z"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test NIMA agent with stream mode"
      ],
      "metadata": {
        "id": "1YjkY4gw3wbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_stream(stream):\n",
        "    \"\"\"\n",
        "     Print the response of NIMA in stream mode.\n",
        "\n",
        "     Parameters:\n",
        "        stream (??): streaming response from NIMA.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    for s in stream:\n",
        "        message = s[\"messages\"][-1]\n",
        "        if isinstance(message, tuple):\n",
        "            print(message)\n",
        "        else:\n",
        "            message.pretty_print()"
      ],
      "metadata": {
        "id": "k1bnUiAVc88K"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing using stream method\n",
        "config = {\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}}  # Configuration for memory storage\n",
        "inputs = {\"messages\": [(\"user\", \"yohi love you\")]}\n",
        "print_stream(graph.stream(inputs, stream_mode=\"values\", config = config))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qr2Cv_Fc_Uk",
        "outputId": "0b68dcb1-a27d-494d-f988-a74b2e260315"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "yohi love you\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  input_judgement_tool (call_oqylrZIxozUGtpN5DBEgzTt8)\n",
            " Call ID: call_oqylrZIxozUGtpN5DBEgzTt8\n",
            "  Args:\n",
            "    user_input: yohi love you\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: input_judgement_tool\n",
            "\n",
            "content='NO' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 29, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_39a40c96a0', 'finish_reason': 'stop', 'logprobs': None} id='run-9415bb16-1d55-49c3-9182-9fdc5f104dd1-0' usage_metadata={'input_tokens': 29, 'output_tokens': 1, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I appreciate your kind words! However, I'm here to assist you with movie-related topics. If you have any questions or need recommendations about films, feel free to ask!\n"
          ]
        }
      ]
    }
  ]
}